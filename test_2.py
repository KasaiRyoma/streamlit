import base64
import time
import streamlit as st
import random
from langchain_openai import ChatOpenAI
from PIL import Image
from io import BytesIO

def load_font_base64(font_path):
    with open(font_path, "rb") as font_file:
        font_base64 = base64.b64encode(font_file.read()).decode()
    return font_base64

def apply_font(font_base64, font_size, line_height):
    st.markdown(
        f"""
        <style>
            @font-face {{
                font-family: 'DynamicFont';
                src: url(data:font/ttf;base64,{font_base64}) format('truetype');
            }}
            .dynamic-text {{
                font-family: 'DynamicFont', sans-serif;
                display: flex;
                height: 70vh; /* é«˜ã•ã‚’ç”»é¢å…¨ä½“ã«è¨­å®š */
                align-items: center;
                justify-content: center; 
                font-size: {font_size};
                line-height: {line_height};
            }}
        </style>
        """,
        unsafe_allow_html=True
    )

def load_audio_base64(audio_path):
    with open(audio_path, "rb") as audio_file:
        audio_base64 = base64.b64encode(audio_file.read()).decode()
        audio_html = f"""
        <audio autoplay=True>
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
        </audio>
        """
    return audio_html

def image_base64(camera_input):
    captured_image = Image.open(BytesIO(camera_input.getvalue()))
    buffered = BytesIO()
    captured_image.save(buffered, format="JPEG")
    image_base64 = base64.b64encode(buffered.getvalue()).decode()
    return image_base64

def init_page():
    st.set_page_config(page_title="è‡ªå‹•ç”»åƒã‚»ãƒªãƒ•ç”Ÿæˆ", page_icon="ğŸ¤–", layout="wide")
    st.markdown(
        """
        <style>
            /* ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã€ãƒ•ãƒƒã‚¿ãƒ¼éè¡¨ç¤º */
            [data-testid="stHeader"], [data-testid="stToolbar"], footer {
                display: none;
            }
            /* ã‚¢ãƒ—ãƒªå…¨ä½“ã®èƒŒæ™¯é»’*/
            [data-testid="stAppViewContainer"] {
                background-color: black;
                color: white;
            }
            /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®èƒŒæ™¯é»’*/
            [data-testid="stMain"] {
                background-color: black;
                color: white;
            }
            /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯è‰²ã¨æ–‡å­—è‰²ã‚’åˆæœŸçŠ¶æ…‹ã«æˆ»ã™ */
            [data-testid="stSidebar"] {
                color: initial;
            }
        </style>
        """,
        unsafe_allow_html=True
    )

def chatgpt(llm, text, image_base64=None):
    query = [
        (
            "user",
            [
                {"type": "text", "text": text},
            ]
        )
    ]
    if image_base64:
        query[0][1].append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{image_base64}",
                "detail": "auto"
            }
        })
    response = llm.invoke(query).content.strip()
    return response

def main():
    init_page()
    audio_placeholder = st.empty()
    audio_placeholder.empty()
    time.sleep(0.5)
    llm = ChatOpenAI(
        temperature=0,
        model="gpt-4o",
        max_tokens=512
    )

    text_length = st.sidebar.selectbox("æ–‡å­—æ•°", [50, 100, 150, 200, "ãƒ©ãƒ³ãƒ€ãƒ "], index=1)
    if text_length == "ãƒ©ãƒ³ãƒ€ãƒ ":
        text_length = random.choice([50, 100, 150, 200])

    mood = st.sidebar.selectbox("é›°å›²æ°—", ["æ˜ã‚‹ã„", "æš—ã„", "ã‚³ãƒ¡ãƒ‡ã‚£", "ãƒ›ãƒ©ãƒ¼", "é›‘å­¦", "ãƒ©ãƒ³ãƒ€ãƒ ", ], index=0)
    if mood == "ãƒ©ãƒ³ãƒ€ãƒ ":
        mood = random.choice(["æ˜ã‚‹ã„", "æš—ã„", "ã‚³ãƒ¡ãƒ‡ã‚£", "ãƒ›ãƒ©ãƒ¼", "é›‘å­¦"])

    font_size = st.sidebar.selectbox("ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º", ["å°", "ä¸­", "å¤§"], index=1)

    sound_f = st.sidebar.radio("åŠ¹æœéŸ³", ["ã‚ªãƒ³", "ã‚ªãƒ•"], index=1)

    kana = st.sidebar.radio("ã²ã‚‰ãŒãªãƒ¢ãƒ¼ãƒ‰", ["ã‚ªãƒ³", "ã‚ªãƒ•"], index=1)
    
    camera_input = st.sidebar.camera_input("æ’®å½±ã—ã¦ãã ã•ã„")

    if camera_input:
        if mood == "é›‘å­¦":
            query1_text = (
                "ã“ã®ç”»åƒã«ã¯ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿå˜èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
                "å˜èªä»¥å¤–ã®æ–‡ç« ã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"
            )
        else:
            query1_text = (
                "ã“ã®ç”»åƒã«ã¯ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿã§ãã‚‹ã ã‘ãŸãã•ã‚“å˜èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
                "å˜èªä»¥å¤–ã®æ–‡ç« ã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"
            )
        response1 = chatgpt(llm, query1_text, image_base64(camera_input))        

        if mood == "é›‘å­¦":
            query2_text = {
                "ã‚ªãƒ³": (
                    f"'{response1}'ã«é–¢ã™ã‚‹é›‘å­¦ã‚„è±†çŸ¥è­˜ã‚’{text_length}å­—ç¨‹åº¦ã§è€ƒãˆãªã•ã„ã€‚"
                    f"å‡ºåŠ›ã¯æ–‡ç« ã®ã¿ã¨ã™ã‚‹ã“ã¨ã€‚"
                    f"å¯èƒ½ã§ã‚ã‚Œã°ãã®çŠ¶æ³ã«ã‚ã£ãŸçµµæ–‡å­—ãªã©ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚"
                    f"æ¼¢å­—ã¯ä½¿ã‚ãšã«ã™ã¹ã¦ã²ã‚‰ãŒãªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    f"å£èª¿ã‚’å­ä¾›å‘ã‘ã«ã—ã¦ãã ã•ã„ã€‚"
                ),
                "ã‚ªãƒ•": (
                    f"'{response1}'ã«é–¢ã™ã‚‹é›‘å­¦ã‚„è±†çŸ¥è­˜ã‚’{text_length}å­—ç¨‹åº¦ã§è€ƒãˆãªã•ã„ã€‚"
                    f"å‡ºåŠ›ã¯æ–‡ç« ã®ã¿ã¨ã™ã‚‹ã“ã¨ã€‚"
                    f"å¯èƒ½ã§ã‚ã‚Œã°ãã®çŠ¶æ³ã«ã‚ã£ãŸçµµæ–‡å­—ãªã©ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚"
                ),
            }
        else:
            query2_text = {
                "ã‚ªãƒ³": (
                    f"'{response1}'ã‚’ç”¨ã„ãŸæ–‡ç« ã‚’{text_length}å­—ç¨‹åº¦ã§è€ƒãˆãªã•ã„ã€‚"
                    f"å‡ºåŠ›ã¯æ–‡ç« ã®ã¿ã¨ã™ã‚‹ã“ã¨ã€‚"
                    f"å¯èƒ½ã§ã‚ã‚Œã°ãã®çŠ¶æ³ã«ã‚ã£ãŸçµµæ–‡å­—ãªã©ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚"
                    f"'{response1}'ä»¥å¤–ã®ã‚‚ã®ã¯ã§ãã‚‹ã ã‘è©±ã«ç™»å ´ã•ã›ãªã„ã“ã¨ã€‚"
                    f"æ–‡ç« ã®é›°å›²æ°—ã¯{mood}ã«ã—ã¦ãã ã•ã„ã€‚"
                    f"æ¼¢å­—ã¯ä½¿ã‚ãšã«ã™ã¹ã¦ã²ã‚‰ãŒãªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    f"å£èª¿ã‚’å­ä¾›å‘ã‘ã«ã—ã¦ãã ã•ã„ã€‚"
                ),
                "ã‚ªãƒ•": (
                    f"'{response1}'ã‚’ç”¨ã„ãŸæ–‡ç« ã‚’{text_length}å­—ç¨‹åº¦ã§è€ƒãˆãªã•ã„ã€‚"
                    f"å‡ºåŠ›ã¯æ–‡ç« ã®ã¿ã¨ã™ã‚‹ã“ã¨ã€‚"
                    f"å¯èƒ½ã§ã‚ã‚Œã°ãã®çŠ¶æ³ã«ã‚ã£ãŸçµµæ–‡å­—ãªã©ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚"
                    f"'{response1}'ä»¥å¤–ã®ã‚‚ã®ã¯ã§ãã‚‹ã ã‘è©±ã«ç™»å ´ã•ã›ãªã„ã“ã¨ã€‚"
                    f"æ–‡ç« ã®é›°å›²æ°—ã¯{mood}ã«ã—ã¦ãã ã•ã„ã€‚"
                ),
            }
        response2 = chatgpt(llm, query2_text[kana])   

        font_path = {
            "æ˜ã‚‹ã„": "./font/001Shirokuma-Regular.otf",
            "æš—ã„": "./font/OtsutomeFont_Ver3_16.ttf",
            "ã‚³ãƒ¡ãƒ‡ã‚£": "./font/PopRumCute.otf",
            "ãƒ›ãƒ©ãƒ¼": "./font/onryou.TTF",
            "é›‘å­¦": "./font/komorebi-gothic.ttf"
        }
        font_settings = {
            "å°": {50: ("2.9em", "1.5"), 100: ("2.3em", "1.3"), 150: ("2.0em", "1.0"), 200: ("1.8em", "1.0")},
            "ä¸­": {50: ("6.0em", "1.5"), 100: ("4.3em", "1.3"), 150: ("3.7em", "1.0"), 200: ("3.5em", "1.0")},
            "å¤§": {50: ("7.0em", "1.5"), 100: ("5.3em", "1.3"), 150: ("4.4em", "1.0"), 200: ("4.2em", "1.0")},
        }
        apply_font(load_font_base64(font_path[mood]), *font_settings[font_size][text_length])

        st.markdown(
            f"""
            <div class="dynamic-text">
                {response1}
            </div>
            """,
            unsafe_allow_html=True
        )

        if sound_f == "ã‚ªãƒ³":
            audio_path = {
                "æ˜ã‚‹ã„": "./audio/akarui.mp3",
                "æš—ã„": "./audio/kurai.mp3",
                "ã‚³ãƒ¡ãƒ‡ã‚£": "./audio/omosiro.mp3",
                "ãƒ›ãƒ©ãƒ¼": "./audio/horror.mp3",
                "é›‘å­¦": "./audio/zatugaku.mp3"
            }
            audio_placeholder.markdown(load_audio_base64(audio_path[mood]), unsafe_allow_html=True)
     
if __name__ == '__main__':
    main()
